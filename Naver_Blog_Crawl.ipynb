{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 검색 API예제는 블로그를 비롯 전문자료까지 호출방법이 동일하므로 blog검색만 대표로 예제를 올렸습니다.\n",
    "# 네이버 검색 Open API 예제 - 블로그 검색\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import urllib3\n",
    "import requests\n",
    "import json\n",
    "import xmltodict\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Hide Warnings\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "client_id = \"VyJ4vDh18O7CVkYDCROr\"\n",
    "client_secret = \"pOn2vw75sv\"\n",
    "\n",
    "# 프라엘 갈바닉, LG전자 디오스 냉장고, 스피커, LG홈브루\n",
    "SEARCH_KEYWORD = \"프라엘 갈바닉\"\n",
    "SEARCH_KEYWORDS = [\"스매그냉장고\", \"다이슨선풍기\", \"LG프라엘\", \"힐링미안마의자\", \"스탠바이미\", \"발뮤다토스터\",\"다이슨에어랩\",\n",
    "                \"LG공기청정기\", \"LG퓨리케어공기청정기\", \"LG스타일러\", \"단미와플메이커\",\n",
    "               \"오아가습기\", \"LG시네빔\", \"LG올레드tv\", \"lgoledtv\", \"뱅앤올룹슨\", \"bangandolufsen\", \"프라엘갈바닉\", \n",
    "               \"LG디오스냉장고\", \"디오스냉장고\", \"마샬스피커\", \"LG홈브루\"]\n",
    "\n",
    "# url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://m.blog.naver.com/PostView.naver?blogId=herdsman77&logNo=222323799763&proxyReferer=\"\n",
    "blog_soup = BeautifulSoup(requests.get(url, verify = False).text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_contents_dict = defaultdict(list)\n",
    "\n",
    "blog_body = blog_soup.find(\"div\", attrs={\"class\":\"se-main-container\"})\n",
    "\n",
    "# 본문 내에 Image와 Text가 있는 부분만 추출\n",
    "blog_img_txt = blog_body.findAll(\"div\", attrs={\"class\" : [re.compile(r\"se-(module|section)-text\"), re.compile(r\"se-(module|section)-image\")]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_body.findAll(\"div\", attrs={\"class\" : [re.compile(r\"se-(module|section)-text\"), re.compile(r\"se-(module|section)-image\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<img alt=\"\" class=\"se-image-resource\" data-height=\"590\" data-lazy-src=\"https://mblogthumb-phinf.pstatic.net/MjAyMTA0MjdfMTkz/MDAxNjE5NTE0MTMzMTY0.m9M-AflEDCR8EN6PN6EuRwxovKlVZarCvnFpWUYZsf8g.0-iCeduazKxNDC5L2N6xjqWJTeygZzl_TSK6Qhb2LTIg.JPEG.herdsman77/00.jpg?type=w800\" data-width=\"886\" src=\"https://mblogthumb-phinf.pstatic.net/MjAyMTA0MjdfMTkz/MDAxNjE5NTE0MTMzMTY0.m9M-AflEDCR8EN6PN6EuRwxovKlVZarCvnFpWUYZsf8g.0-iCeduazKxNDC5L2N6xjqWJTeygZzl_TSK6Qhb2LTIg.JPEG.herdsman77/00.jpg?type=w80_blur\">\n",
       "</img>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_img_txt[0].select_one(\"img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image 파일 이름과 블로그 글을 하나의 contents로 엮어서 text 생성\n",
    "raw_blog_contents = []\n",
    "img_urls = []\n",
    "img_names = []\n",
    "img_num = 0\n",
    "for x in blog_img_txt:\n",
    "    if any([re.findall(r\"se-module-image|se-section-image\", y) for y in x.attrs[\"class\"]]):\n",
    "        \n",
    "        if \"data-lazy-src\" in x.select_one(\"img\").attrs.keys():\n",
    "            img_url = x.select_one(\"img\")[\"data-lazy-src\"]\n",
    "        else:\n",
    "            img_url = x.select_one(\"img\")[\"src\"]\n",
    "        \n",
    "        if img_url in img_urls:\n",
    "            continue\n",
    "        else:\n",
    "            img_urls.append(img_url)\n",
    "\n",
    "        bloggername = re.sub(r'/|\\.|\\*|%|\\\\|:|\\?|\\\"|\\'|\\<|\\>|\\|','_',bloggername)\n",
    "        \n",
    "        img_num += 1\n",
    "        img_name = f\"img_{img_num}.jpg\"\n",
    "        img_names.append(img_name)\n",
    "        raw_blog_contents.append(img_name)\n",
    "        \n",
    "    elif \"se-module-text\" in x.attrs[\"class\"]:\n",
    "        text = x.get_text()\n",
    "        raw_blog_contents.append(text)\n",
    "\n",
    "blog_contents = \"\\n\".join(raw_blog_contents)\n",
    "\n",
    "blog_contents_dict[\"contents\"] = blog_contents\n",
    "blog_contents_dict[\"images\"] = img_names\n",
    "blog_contents_dict[\"image_urls\"] = img_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naver_blog_crawl = NaverBlogCrawl()\n",
    "result = naver_blog_crawl.collect_blog(keywords = SEARCH_KEYWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"blog.naver\" in \"blog.naver.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaverBlogCrawl:\n",
    "    \n",
    "    client_id = \"VyJ4vDh18O7CVkYDCROr\"\n",
    "    client_secret = \"pOn2vw75sv\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    def search_blogs_by_API(self, keyword):\n",
    "        blog_infos = defaultdict(list)\n",
    "        self.keyword = keyword\n",
    "        # API를 통한 검색\n",
    "        encText = urllib.parse.quote(self.keyword)\n",
    "        url = f\"https://openapi.naver.com/v1/search/blog.xml?query={encText}&display=30\"\n",
    "\n",
    "        headers = {\"X-Naver-Client-Id\" : self.client_id,\n",
    "                   \"X-Naver-Client-Secret\" : self.client_secret}\n",
    "        rq = requests.get(url, headers=headers, verify=False)\n",
    "        html = rq.text\n",
    "        html_dict = xmltodict.parse(html)\n",
    "\n",
    "        # Blog URL들만 추출\n",
    "        blog_infos[\"urls\"] = [x[\"link\"] for x in html_dict[\"rss\"][\"channel\"][\"item\"] if \"blog.naver\" in x[\"link\"]]\n",
    "        blog_infos[\"bloggernames\"] = [x[\"bloggername\"] for x in html_dict[\"rss\"][\"channel\"][\"item\"] if \"blog.naver\" in x[\"link\"]]\n",
    "        blog_infos[\"postdates\"] = [x[\"postdate\"] for x in html_dict[\"rss\"][\"channel\"][\"item\"] if \"blog.naver\" in x[\"link\"]]\n",
    "\n",
    "        \n",
    "        return blog_infos\n",
    "\n",
    "\n",
    "\n",
    "    def find_real_url(self, url):\n",
    "        # 실제 Url 찾기\n",
    "        url_rq = requests.get(url, verify=False)\n",
    "\n",
    "        soup = BeautifulSoup(url_rq.text, \"html.parser\")\n",
    "\n",
    "        blog_url = f\"https://blog.naver.com/{soup.select_one('iframe')['src']}\"\n",
    "        \n",
    "        return blog_url\n",
    "\n",
    "\n",
    "\n",
    "    def save_images(self, img_urls, img_names, img_dir = \"./image\"):\n",
    "\n",
    "        if img_dir is None:\n",
    "            img_dir = f\"./image/{self.keyword}\"\n",
    "        \n",
    "        if not os.path.exists(img_dir):\n",
    "            os.makedirs(img_dir)\n",
    "\n",
    "        self.error_list = []\n",
    "        for img_url, img_name in zip(img_urls, img_names):\n",
    "            # image 저장        \n",
    "            try:\n",
    "                img_rq = requests.get(img_url, verify = False)\n",
    "                with open(f\"{img_dir}/{img_name}\", \"wb\") as f:\n",
    "                    f.write(img_rq.content)\n",
    "            except: \n",
    "                self.error_list.append(img_name)\n",
    "                print(f\"img_name : {img_name}, img_url : {img_url}\")\n",
    "\n",
    "    \n",
    "\n",
    "    def parse_smarteditor_one(self, blog_soup, bloggername, postdate):\n",
    "        blog_contents_dict = defaultdict(list)\n",
    "\n",
    "        blog_body = blog_soup.find(\"div\", attrs={\"class\":\"se-main-container\"})\n",
    "\n",
    "        # 본문 내에 Image와 Text가 있는 부분만 추출\n",
    "        blog_img_txt = blog_body.findAll(\"div\", attrs={\"class\" : [re.compile(r\"se-(module|section)-text\"), re.compile(r\"se-(module|section)-image\")]})\n",
    "\n",
    "        # image 파일 이름과 블로그 글을 하나의 contents로 엮어서 text 생성\n",
    "        raw_blog_contents = []\n",
    "        img_urls = []\n",
    "        img_names = []\n",
    "        img_num = 0\n",
    "        for x in blog_img_txt:\n",
    "            if any([re.findall(r\"se-module-image|se-section-image\", y) for y in x.attrs[\"class\"]]):\n",
    "                \n",
    "                if \"data-lazy-src\" in x.select_one(\"img\").attrs.keys():\n",
    "                    img_url = x.select_one(\"img\")[\"data-lazy-src\"]\n",
    "                else:\n",
    "                    img_url = x.select_one(\"img\")[\"src\"]\n",
    "                \n",
    "                if img_url in img_urls:\n",
    "                    continue\n",
    "                else:\n",
    "                    img_urls.append(img_url)\n",
    "                \n",
    "                img_num += 1\n",
    "                bloggername = re.sub(r'/|\\.|\\*|%|\\\\|:|\\?|\\\"|\\'|\\<|\\>|\\|','_',bloggername)\n",
    "                img_name = f\"{self.keyword}_{bloggername}_{postdate}_img_{img_num}.jpg\"\n",
    "                img_names.append(img_name)\n",
    "                raw_blog_contents.append(img_name)\n",
    "            elif \"se-module-text\" in x.attrs[\"class\"]:\n",
    "                text = x.get_text()\n",
    "                raw_blog_contents.append(text)\n",
    "\n",
    "        blog_contents = \"\\n\".join(raw_blog_contents)\n",
    "        \n",
    "        blog_contents_dict[\"contents\"] = blog_contents\n",
    "        blog_contents_dict[\"images\"] = img_names\n",
    "        blog_contents_dict[\"image_urls\"] = img_urls\n",
    "\n",
    "        return blog_contents_dict\n",
    "\n",
    "\n",
    "    def parse_smarteditor_new(self, blog_soup, bloggername, postdate):\n",
    "        blog_contents_dict = defaultdict(list)\n",
    "\n",
    "        # 본문 내에 Image와 Text가 있는 부분만 추출\n",
    "        blog_body = blog_soup.find(\"div\", attrs = {\"class\":\"se_component_wrap sect_dsc __se_component_area\"})\n",
    "        blog_img_txt = blog_body.findAll(\"div\", attrs={\"class\" : [\"se_component se_paragraph default\", \"se_component se_image default\"]})\n",
    "\n",
    "        # image 파일 이름과 블로그 글을 하나의 contents로 엮어서 text 생성\n",
    "        raw_blog_contents = []\n",
    "        img_urls = []\n",
    "        img_names = []\n",
    "        img_num = 0\n",
    "        for x in blog_img_txt:\n",
    "            if \"se_image\" in x.attrs[\"class\"]:\n",
    "                img_num += 1\n",
    "                if \"data-lazy-src\" in x.select_one(\"img\").attrs.keys():\n",
    "                    img_urls.append(x.select_one(\"img\")[\"data-lazy-src\"])\n",
    "                else:\n",
    "                    img_urls.append(x.select_one(\"img\")[\"src\"])\n",
    "                bloggername = re.sub(r'/|\\.|\\*|%|\\\\|:|\\?|\\\"|\\'|\\<|\\>|\\|','_',bloggername)\n",
    "                img_name = f\"{self.keyword}_{bloggername}_{postdate}_img_{img_num}.jpg\"\n",
    "                img_names.append(img_name)\n",
    "                raw_blog_contents.append(img_name)\n",
    "            elif \"se_paragraph\" in x.attrs[\"class\"]:\n",
    "                text = x.get_text()\n",
    "                raw_blog_contents.append(text)\n",
    "\n",
    "        blog_contents = \"\\n\".join(raw_blog_contents)\n",
    "        \n",
    "        blog_contents_dict[\"contents\"] = blog_contents\n",
    "        blog_contents_dict[\"images\"] = img_names\n",
    "        blog_contents_dict[\"image_urls\"] = img_urls\n",
    "\n",
    "        return blog_contents_dict\n",
    "\n",
    "\n",
    "\n",
    "    def parse_smarteditor_2(self, blog_soup, bloggername, postdate):\n",
    "        blog_contents_dict = defaultdict(list)\n",
    "\n",
    "        # 본문 내에 Image와 Text가 있는 부분만 추출\n",
    "        blog_body = blog_soup.find(\"div\", attrs = {\"id\":\"postViewArea\"})\n",
    "        blog_img_txt = blog_body.findAll(\"p\")\n",
    "\n",
    "        # image 파일 이름과 블로그 글을 하나의 contents로 엮어서 text 생성\n",
    "        raw_blog_contents = []\n",
    "        img_urls = []\n",
    "        img_names = []\n",
    "        img_num = 0\n",
    "        for x in blog_img_txt:\n",
    "            if x.find(\"img\", attrs={\"class\": \"_photoImage\"}) is not None:\n",
    "                img_num += 1\n",
    "                if \"data-lazy-src\" in x.select_one(\"img\", attrs={\"class\": \"_photoImage\"}).attrs.keys():\n",
    "                    img_urls.append(x.select_one(\"img\", attrs={\"class\": \"_photoImage\"})[\"data-lazy-src\"])\n",
    "                else:\n",
    "                    img_urls.append(x.select_one(\"img\", attrs={\"class\": \"_photoImage\"})[\"src\"])\n",
    "                bloggername = re.sub(r'/|\\.|\\*|%|\\\\|:|\\?|\\\"|\\'|\\<|\\>|\\|','_',bloggername)\n",
    "                img_name = f\"{self.keyword}_{bloggername}_{postdate}_img_{img_num}.jpg\"\n",
    "                img_names.append(img_name)\n",
    "                raw_blog_contents.append(img_name)\n",
    "\n",
    "                text = x.get_text()\n",
    "                raw_blog_contents.append(text)\n",
    "            else:\n",
    "                text = x.get_text()\n",
    "                raw_blog_contents.append(text)\n",
    "\n",
    "        blog_contents = \"\\n\".join(raw_blog_contents)\n",
    "\n",
    "        blog_contents_dict[\"images\"] = img_names\n",
    "        blog_contents_dict[\"image_urls\"] = img_urls\n",
    "        blog_contents_dict[\"contents\"] = blog_contents\n",
    "\n",
    "        return blog_contents_dict\n",
    "\n",
    "\n",
    "\n",
    "    def extract_contents(self, blog_url, bloggername, postdate):\n",
    "        \n",
    "        # Blog URL에서 작성자, 날짜, 본문 추출\n",
    "        blog_rq = requests.get(blog_url, verify=False)\n",
    "        blog_soup = BeautifulSoup(blog_rq.text, \"html.parser\")\n",
    "\n",
    "        self.blog_soup = blog_soup\n",
    "        # # 작성자 ID\n",
    "        # writer_name = blog_soup.find(\"span\", attrs = {\"class\" : \"nick\"}).get_text().replace(\" \", \"_\")\n",
    "\n",
    "        # # 날짜\n",
    "        # post_date = blog_soup.find(\"span\", attrs = {\"class\" : \"se_publishDate pcol2\"}).get_text().replace(\" \", \"\")\n",
    "        # post_date = re.sub(\"\\\\.|:|\\s\", \"_\", post_date)\n",
    "\n",
    "        # 블로그 본문\n",
    "        if self.blog_soup.find(\"div\", attrs={\"id\" : \"postViewArea\"}):\n",
    "            blog_contents_dict = self.parse_smarteditor_2(self.blog_soup, bloggername, postdate)\n",
    "        elif self.blog_soup.find(\"div\", attrs={\"class\" : \"se-main-container\"}):\n",
    "            blog_contents_dict = self.parse_smarteditor_one(self.blog_soup, bloggername, postdate)\n",
    "        elif self.blog_soup.find(\"div\", attrs = {\"class\":\"se_component_wrap sect_dsc __se_component_area\"}):\n",
    "            blog_contents_dict = self.parse_smarteditor_new(self.blog_soup, bloggername, postdate)\n",
    "\n",
    "\n",
    "        return blog_contents_dict\n",
    "\n",
    "\n",
    "\n",
    "    def collect_blog(self, keywords):\n",
    "        self.result_dict = defaultdict(list)\n",
    "        if not isinstance(keywords, list):\n",
    "            self.keywords = [keywords]\n",
    "        else:\n",
    "            self.keywords = keywords\n",
    "        \n",
    "        for keyword in self.keywords:\n",
    "            self.blog_infos = self.search_blogs_by_API(keyword)\n",
    "            print(f\"keyword : {keyword}, # of blogs : {len(self.blog_infos['urls'])}\")\n",
    "            \n",
    "            img_dir = os.path.join(\"./image\", keyword)\n",
    "\n",
    "            for i, (url, bloggername, postdate) in enumerate(zip(self.blog_infos[\"urls\"], self.blog_infos[\"bloggernames\"], self.blog_infos[\"postdates\"])):\n",
    "                print(i, end = \",\")\n",
    "                self.blog_url = self.find_real_url(url)\n",
    "                self.blog_contents_dict = self.extract_contents(self.blog_url, bloggername, postdate)\n",
    "                self.save_images(self.blog_contents_dict[\"image_urls\"], self.blog_contents_dict[\"images\"], img_dir = img_dir)\n",
    "                \n",
    "                self.result_dict[\"keyword\"].append(keyword)\n",
    "                self.result_dict[\"writer_name\"].append(bloggername)\n",
    "                self.result_dict[\"post_date\"].append(postdate)\n",
    "                self.result_dict[\"blog_url\"].append(self.blog_url)\n",
    "                self.result_dict[\"contents\"].append(self.blog_contents_dict[\"contents\"])\n",
    "                self.result_dict[\"images\"].append(self.blog_contents_dict[\"images\"])\n",
    "                self.result_dict[\"image_urls\"].append(self.blog_contents_dict[\"image_urls\"])\n",
    "            print(\"\", end = \"\\n\")\n",
    "        \n",
    "            pd.DataFrame(self.result_dict).to_excel(f\"{self.keyword}.xlsx\", index = False, encoding = \"CP949\")\n",
    "        return self.result_dict\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3ac812946b33dd348792ce29ac44caaf581a692bf5bf55f347f7b85af932a67"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
